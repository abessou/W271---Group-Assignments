---
title: "Homework 3"
author: "Rohan Thakur, Charles Kekeh and Megan Jasek"
date: "February 13, 2016"
output: pdf_document
---

```{r,include=FALSE}
library(ggplot2)
library(boot)
library(pastecs)
library(car)
library(knitr)
library(sandwich)
library(lmtest)
opts_chunk$set(tidy.opts=list(width.cutoff=50))
```

```{r, tidy=TRUE, tidy.opts=list(width.cutoff=50)}
# Load the dataframe
load("twoyear.RData")
desc
```

Question 1
==========
```{r, tidy=TRUE, tidy.opts=list(width.cutoff=50)}
summary(data$lwage)
print(quantile(data$lwage, probs = c(.01, .05, .10, .25, .50, .75, .90, .95, .99, 1)))
hist(data$lwage, 50, ylim=c(0,350))

summary(data$jc)
print(quantile(data$jc, probs = c(.01, .05, .10, .25, .50, .75, .90, .95, .99, 1)))
hist(data$jc, 50)

summary(data$univ)
print(quantile(data$univ, probs = c(.01, .05, .10, .25, .50, .75, .90, .95, .99, 1)))
hist(data$univ, 50, xlim=c(0,8))

summary(data$exper)
print(quantile(data$exper, probs = c(.01, .05, .10, .25, .50, .75, .90, .95, .99, 1)))
hist(data$exper, 50, xlim=c(0,200))

summary(data$black)
print(quantile(data$black, probs = c(.01, .05, .10, .25, .50, .75, .90, .95, .99, 1)))
hist(data$black, 50)

summary(data$hispanic)
print(quantile(data$hispanic, probs = c(.01, .05, .10, .25, .50, .75, .90, .95, .99, 1)))
hist(data$hispanic, 50)

summary(data$AA)
print(quantile(data$AA, probs = c(.01, .05, .10, .25, .50, .75, .90, .95, .99, 1)))
hist(data$AA, 50)

summary(data$BA)
print(quantile(data$BA, probs = c(.01, .05, .10, .25, .50, .75, .90, .95, .99, 1)))
hist(data$BA, 50, ylim=c(0,5000))
```

Basic structure of the data
---------------------------
There are no missing values in the data.\newline
__lwage__ variable has a normal-like distribution.\newline
__jc__ variable has values from 0 to about 4 and is heavily positively skewed with a
majority of values at or near 0.\newline
__univ__ variable has values from 0 to 7.5 and is heavily positively skewed with a majority of values at or near 0.\newline
__exper__ variable has values from 0 to 166 and is negatively skewed with a hill-climb distribution from 0 to about 500.\newline
__black, hispanic, AA, BA__ variables are binary with values of 0 or 1.\newline

Question 2
==========
```{r, tidy=TRUE, tidy.opts=list(width.cutoff=50)}
# Create the experXblack variable by multiplying the exper and black variables.
data$experXblack = data$exper*data$black

# Run the requested OLS regression.
ols.lwage.8ind = lm(lwage~jc+univ+exper+black+hispanic+AA+BA+experXblack, data=data)
summary(ols.lwage.8ind)
# Print the diagnostic plots
plot(ols.lwage.8ind)

#Print the B_hat4 and B_hat8 coefficients
print(ols.lwage.8ind$coefficients[5])
print(ols.lwage.8ind$coefficients[9])
```

Interpret the coefficients $\hat{\beta}4$ and $\hat{\beta}8$
------------------------------------------------
$\hat{\beta}4$ is the estimate for the black variable coefficient.\newline
$\hat{\beta}8$ is the estimate for the experXblack variable.\newline
<finish analysis>
Do we talk about:  
zero-conditional mean seems to be met\newline
homoskedasticity seems to be met\newline
assuming random sample\newline
assuming linear relationship\newline

Question 3
==========
```{r, tidy=TRUE, tidy.opts=list(width.cutoff=50)}
# Show the summary of the model again
summary(ols.lwage.8ind)

#Print the univ coefficient
print(ols.lwage.8ind$coefficients[3])

(.0733 - .07) / (.0031)
2*(1-.8554)
```

Test that the return to university education is 7%.
---------------------------------------------------
Null Hypothesis: H0:  $\beta2=0.07$.\newline
Alternate Hypothesis: H1:  $\beta2\neq0.07$.\newline
Formula for t-statistic = $(\beta2-H0)/(se) = (.0733 - .07) / (.0031) = 1.064516$\newline
p-value = $2*(1-.8554) = 0.2892$\newline
Based on the p-value, the test is not significant at the 0.05% significance level.  Therefore, we can't reject the null hypothesis that the return to university education is 7%.

Question 4
==========
```{r, tidy=TRUE, tidy.opts=list(width.cutoff=50)}
```

Test that the return to junior college education is equal for black and non-black
---------------------------------------------------------------------------------
<type answer here>

Question 5
==========

Test whether the return to university education is equal to the return to 1 year of working experience.
-----------------------------------------------------------------------------------
Original model:
$$lwage = \beta0 + \beta1jc+\beta2univ+\beta3exper+\beta4black+\beta5hispanic+\beta6AA+\beta7BA+\beta8experXblack+\epsilon$$

Convert the experience variable from months to years by creating a new variable experYr that divides the original variable exper by 12.  Replace the exper variable in the original model with this variable.
$$lwage = \beta0 + \beta1jc+\beta2univ+\beta3experYr+\beta4black+\beta5hispanic+\beta6AA+\beta7BA+\beta8experXblack+\epsilon$$

We would like to know if the $\beta2$ and $\beta3$ coefficients are the same or, equivalently, if their difference is 0.  We can define a variable $\theta$ such that $\theta = \beta2 - \beta3$ and rewrite our model like this:
$$lwage = \beta0 + \beta1jc+(\theta+\beta3)univ+\beta3experYr+\beta4black+\beta5hispanic+\beta6AA+\beta7BA+\beta8experXblack+\epsilon$$

Rewrite the model to get $\theta$ by itself as a coefficient:
$$lwage = \beta0 + \beta1jc+\theta{univ}+\beta3(univ+experYr)+\beta4black+\beta5hispanic+\beta6AA+\beta7BA+\beta8experXblack+\epsilon$$

Now our null hypothesis is $H0: \theta = 0$.\newline
Alternate Hypothesis: H1:  $\theta\neq0$.\newline

```{r, tidy=TRUE, tidy.opts=list(width.cutoff=50)}
# Convert the exper variable from months to years by dividing it by 12.
data$experYr = data$exper/12
# Create a variable that is the sum of the univ and experYr variables
data$univ_plus_experYr = data$univ + data$experYr
# Rerun the regression with the new variables.
ols.lwage.univ.experYr = lm(lwage~jc+univ+univ_plus_experYr+black+hispanic+AA+BA+experXblack, data=data)
# Display a summary of the new model
summary(ols.lwage.univ.experYr)
```

Based on the very low p-value (0.000276) for $\theta$, the test is significant at the 0.05% significance level.  And even though the value of $\theta$ is close to 0 at 0.0129997, we can reject the null hypothesis that $\theta=0$.

Question 6
==========
```{r, tidy=TRUE, tidy.opts=list(width.cutoff=50)}
# Show the summary of the model again
summary(ols.lwage.8ind)
```

Test the overall significance of this regression.
-------------------------------------------------
We are testing the overall significance of the original model as stated below:
$$lwage = \beta0 + \beta1jc+\beta2univ+\beta3exper+\beta4black+\beta5hispanic+\beta6AA+\beta7BA+\beta8experXblack+\epsilon$$

Here is the output from the summary of the original model.\newline
Residual standard error: 0.4287 on 6754 degrees of freedom\newline
Multiple R-squared:  0.2282,	Adjusted R-squared:  0.2272\newline
F-statistic: 249.6 on 8 and 6754 DF,  p-value: < 2.2e-16\newline

1. Our model null hypothesis is that there is no relationship among any of the independent variables and lwage variable. We are able to reject the null hypothesis since our p-value of the f-statistic of the model is significant at < 2.2e-16.
2. Practical significance: we have an R-squared value of 0.2282, indicating that 22.82% of the variation in lwage is explained by our model.\newline

Question 7
==========
```{r, tidy=TRUE, tidy.opts=list(width.cutoff=50)}
# Define a square term for the exper variable
data$experXexper = data$exper*data$exper
# Add the new variable to the regression
ols.lwage.9ind = lm(lwage~jc+univ+exper+black+hispanic+AA+BA+experXblack+experXexper, data=data)
# Show the summary of the model
summary(ols.lwage.9ind)
```

Estimated return to work experience in this model
-------------------------------------------------
$$lwage = \beta0 + \beta1jc+\beta2univ+\beta3exper+\beta4black+\beta5hispanic+\beta6AA+\beta7BA+\beta8experXblack+\beta9experXexper$$

$$\frac{\delta lwage}{exper} = \beta3 + \beta8black + 2*\beta9exper$$
$\beta3 = 4.301e-03= .004301$, $\beta8 = .001239$, $\beta9 = 000003379$\newline
Substituting these values in the the equation above we get:
$$\frac{\delta lwage}{exper} = (.004301 - .001239*black + .000006758*exper)$$
Now convert the log wage back to wage by exponentiating.  This gives us a return to work experience:
$$ = e^{(.004301 - .001239*black + .000006758*exper)}$$
??is the correct or do we need to multiply it by something else

Question 8
==========
```{r, tidy=TRUE, tidy.opts=list(width.cutoff=50)}
# Plot the graphs from the model
plot(ols.lwage.8ind)
# Just as a precaution, use the robust standard errors
coeftest(ols.lwage.8ind, vcov=vcovHC)
# Show the summary of the model
summary(ols.lwage.8ind)
```

Homoskedasticity analysis:
--------------------------
We are testing homoskedasticity of the original model as stated below:
$$lwage = \beta0 + \beta1jc+\beta2univ+\beta3exper+\beta4black+\beta5hispanic+\beta6AA+\beta7BA+\beta8experXblack+\epsilon$$


The assumption of homoskedasticity holds:\newline
1 - We can see from the residuals vs fitted plot that the variance band is about the same as we move to higher fitted values.\newline
2 - The same story is told by the scale-location plot where we see that the smoothing line is almost completely horizontal, which is what we get if homoskedasticity is met.\newline
3 - We do not look at the Breusch Pagan test since we have a large number of observations, therefore we know almost certainly that we will obtain significance.

The implication of homoskedasticity in the data is that the standard error of the univ coefficient ($\beta2$) is unbiased. Unbiased standard errors will not impact the outcomes of statistical tests.  Therefore, it does not affect the testing of no effect of university education on salary change.

Just as a precaution the model was rerun using robust standard errors.  The $\beta2$ coefficient was essentially unchanged.  In the original model $\beta2 = 0.0732806$ and in the model with robust standard errors $\beta2 = 0.07328063$.